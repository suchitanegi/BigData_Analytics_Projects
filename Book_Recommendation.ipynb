{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path:  D:/Academic/SCU_Q3/BigData/Assignments/HW3/customers_books.txt\n"
     ]
    }
   ],
   "source": [
    "#   DEFINE your input path\n",
    "#input_path = sys.argv[1]\n",
    "input_path = \"D:/Academic/SCU_Q3/BigData/Assignments/HW3/customers_books.txt\"\n",
    "print(\"input_path: \", input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   CREATE an instance of a SparkSession object\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Book_Recommendation_System\")\\\n",
    "    .getOrCreate()\n",
    "    \n",
    "#   To MINIMIZE the Verbosity of Spark we set log level to Warn\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " First five Output from rdd: \n",
      " ['u1:book1', 'u1:book2', 'u1:book2', 'u1:book3', 'u1:book3'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   CREATE a new RDD[String]\n",
    "rdd = spark.sparkContext.textFile(input_path)\n",
    "print(\"\\n First five Output from rdd: \\n\" , rdd.take(5), \"\\n\")\n",
    "\n",
    "#   Remove duplicate values from the input rdd .\n",
    "rdd_unique = rdd.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a set of Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapper Output key-value : \n",
      " [('book2', 'u1'), ('book3', 'u1'), ('book4', 'u1'), ('book5', 'u1'), ('book0', 'u2')] \n",
      "\n",
      "Number of Unique Users: \n",
      " 14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   Mapping key value pair for input data : key - Book , value - user id\n",
    "rdd1 = rdd_unique.map(lambda x:x.split(':')).map(lambda x: (x[1], x[0]))\n",
    "print(\"Mapper Output key-value : \\n\" , rdd1.take(5), \"\\n\")\n",
    "\n",
    "#   Count the total number of unique users\n",
    "count_users=rdd1.map(lambda x: (x[1])).distinct().collect()\n",
    "unique_users = len(count_users)\n",
    "print(\"Number of Unique Users: \\n\" , unique_users , \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five output of (books, userid of users purchased this book): \n",
      " [('book0', ['u2', 'u6', 'u3']), ('book1', ['u1', 'u6', 'u7', 'u8', 'u10', 'u12']), ('book10', ['u8']), ('book11', ['u8', 'u12', 'u9', 'u10', 'u11', 'u1']), ('book12', ['u9', 'u11', 'u3', 'u19', 'u8', 'u12', 'u13'])] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   Group userIds with each bookNumber\n",
    "#This will have all user id in a list for each book purchased.\n",
    "#Book will be the key and values will be list of userIds\n",
    "#output will be in the form: (book#,[user1,user2])\n",
    "\n",
    "rdd_grouped = rdd1.groupByKey().map(lambda k: (k[0], list(k[1])))\n",
    "print(\"First five output of (books, userid of users purchased this book): \\n\",\\\n",
    " rdd_grouped.takeOrdered(5) , \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five output of Cartesian Product : \n",
      " [(('book3', ['u1', 'u5', 'u6', 'u12', 'u13', 'u7']), ('book3', ['u1', 'u5', 'u6', 'u12', 'u13', 'u7'])), (('book3', ['u1', 'u5', 'u6', 'u12', 'u13', 'u7']), ('book4', ['u1', 'u4'])), (('book3', ['u1', 'u5', 'u6', 'u12', 'u13', 'u7']), ('book7', ['u2', 'u1'])), (('book3', ['u1', 'u5', 'u6', 'u12', 'u13', 'u7']), ('book9', ['u3', 'u5', 'u6', 'u1', 'u2', 'u4'])), (('book3', ['u1', 'u5', 'u6', 'u12', 'u13', 'u7']), ('book12', ['u9', 'u11', 'u3', 'u19', 'u8', 'u12', 'u13']))] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   Cartesian product of all combination of bookNumber and userid's of users purchasing each book.\n",
    "cartesian_product_rdd = rdd_grouped.cartesian(rdd_grouped)\n",
    "print(\"First five output of Cartesian Product : \\n\" , cartesian_product_rdd.take(5), \"\\n\")\n",
    "\n",
    "#   Filter out duplicate row representing the same combination in the cartesian matrix.\n",
    "filtered_cartesian_rdd = cartesian_product_rdd.filter(lambda x: x[0] < x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Computing the Correlation for each pair of books \n",
    "#### Creare 4 functions to return values for A,B,C,D that helps arrange the data into a contingency table fro easier correlation calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Function to calculate how many customers purchased same combination of books\n",
    "#Here we want to see how many users have purchased the same book\n",
    "# y-yes if a user purchased both books and otherwise n-no \n",
    "#ex: BookA-yes BookB-Yes\n",
    "#The function returns:Count of users who purchased both book A and bookB\n",
    "\n",
    "def a_same_purchase(y,n):\n",
    "    same_purchase=[]\n",
    "    for uid_y in y[1]:\n",
    "        for uid_n in n[1]:\n",
    "            if uid_y == uid_n:\n",
    "                same_purchase.append(uid_y)\n",
    "    return len(same_purchase)\n",
    "\n",
    "#   Function to calculate how many customers purchased book in\n",
    "#first column of cartesian product but not in second column of cartesian product.\n",
    "#ex: BookA:Yes BookB:No\n",
    "#The function returns:Count of users who purchased book A but didnot purchase bookB\n",
    "\n",
    "def b_purchase(y,n):\n",
    "    users_in_b=[]\n",
    "    for uid_y in y[1]:\n",
    "        if uid_y not in n[1]:\n",
    "            users_in_b.append(uid_y)\n",
    "    return len(users_in_b)\n",
    "\n",
    "#   Function to calculate how many customers purchased book in \n",
    "#second column of cartesian product but not in first column of cartesian product.\n",
    "#ex: BookA:No BookB:Yes\n",
    "#The function returns:Count of users who didnot purchase book A But purchased bookB\n",
    "def c_purchase(y,n):\n",
    "    users_in_c=[]\n",
    "    for uid_n in n[1]:\n",
    "        if uid_n not in y[1]:\n",
    "            users_in_c.append(uid_n)\n",
    "    return len(users_in_c)\n",
    "\n",
    "#  Function to calculate how many users have not purchased either of two books at all\n",
    "#Here we take the total number of unique users and\n",
    "#subtract them from users who made same purchase or either one of the purchase of that book.\n",
    "#ex: BookA:No BookB:No\n",
    "#The function returns:Count of users who didnot purchase book A and bookB\n",
    "    \n",
    "def d_no_purchase(y,n):\n",
    "    any_purchase = a_same_purchase(y,n)+ b_purchase(y,n) + c_purchase(y,n)\n",
    "    no_purchase = unique_users - any_purchase\n",
    "    return no_purchase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate phi correlation \n",
    "- By using values returend by defined functions to apply in pearson's formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function and calculate phi values for each combination of books purchased by users in cartesian product.\n",
    "#The phi-correlation value is two way,that is corr(bookA,bookB) = corr(bookB,bookA)\n",
    "#The phi_corr function defines the sparse similarity matrix \n",
    "#to genereate the phi correlation value for each book pair.\n",
    "\n",
    "def phi_corr(val):\n",
    "    a = a_same_purchase(val[0],val[1])\n",
    "    b = b_purchase(val[0],val[1])\n",
    "    c = c_purchase(val[0],val[1])\n",
    "    d = d_no_purchase(val[0],val[1])\n",
    "    phi_correlation = ((a*d)-(b*c))/(sqrt((a+b)*(c+d)*(a+c)*(b+d)))\n",
    "    return (val[0][0],val[1][0],phi_correlation),(val[1][0],val[0][0],phi_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 output of all pairs of book purchased with their phi correlation: \n",
      " [('book0', 'book1', -0.10050378152592121), ('book0', 'book10', -0.14484136487558028), ('book0', 'book11', -0.45226701686664544), ('book0', 'book12', -0.17407765595569785), ('book0', 'book13', 0.5310850045437943)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   The filtered caterisian product of users and book is passed to the flatMap\n",
    "# to get the correlation between two books\n",
    "book_corr_rdd = filtered_cartesian_rdd.flatMap(phi_corr)\n",
    "#   Printing phi correlations of the pairs of books purchased\n",
    "print(\"First 5 output of all pairs of book purchased with their phi correlation: \\n\",\\\n",
    "      book_corr_rdd.takeOrdered(5), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 output of Top two pairs of book purchased with highest correlation value : \n",
      " [('book0', 'book13', 0.5310850045437943), ('book0', 'book9', 0.6030226891555273), ('book1', 'book11', 0.4166666666666667), ('book1', 'book3', 0.4166666666666667), ('book10', 'book11', 0.32025630761017426)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   Top 2 book combinations with highest phi correlation \n",
    "#For each book combination, we select book with the top 2 largest values of phi.\n",
    "#If two book pair have same correlation value then any of the combination is picked by spark.\n",
    "top_two_phi = book_corr_rdd.groupBy(lambda x: x[0]).\\\n",
    "flatMap(lambda g: nlargest(2, g[1], key=lambda x: x[2]))\n",
    "#   Printing Top two pairs of book purchased with their phi correlation\n",
    "print(\"First 5 output of Top two pairs of book purchased with highest correlation value : \\n\",\\\n",
    "      top_two_phi.takeOrdered(5), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities have been calculated for every pair of books and the top 2 books are the recommendation based on user purchase,\n",
    "- if a user buys a particular book ,based on the phi correlation value,the algorithm recommends two other books that user have bought which is highly correlated with the purchase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "book_rdd = top_two_phi.map(lambda x: (x[0],x[1])).\\\n",
    "        groupByKey().map(lambda k: (k[0], list(k[1]))).\\\n",
    "        sortBy(lambda a: a[0])\n",
    "        \n",
    "#   Collect values of each book recommending other two books as per user purchase.\n",
    "book_recommended = book_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Books Recommendation as per customer purchase : \n",
      "\n",
      "Customers Who Bought  book0 Also Bought:  book9 , book13 \n",
      "\n",
      "Customers Who Bought  book1 Also Bought:  book3 , book11 \n",
      "\n",
      "Customers Who Bought  book10 Also Bought:  book6 , book11 \n",
      "\n",
      "Customers Who Bought  book11 Also Bought:  book19 , book22 \n",
      "\n",
      "Customers Who Bought  book12 Also Bought:  book16 , book15 \n",
      "\n",
      "Customers Who Bought  book13 Also Bought:  book0 , book16 \n",
      "\n",
      "Customers Who Bought  book15 Also Bought:  book16 , book12 \n",
      "\n",
      "Customers Who Bought  book16 Also Bought:  book15 , book13 \n",
      "\n",
      "Customers Who Bought  book17 Also Bought:  book7 , book0 \n",
      "\n",
      "Customers Who Bought  book18 Also Bought:  book19 , book11 \n",
      "\n",
      "Customers Who Bought  book19 Also Bought:  book18 , book11 \n",
      "\n",
      "Customers Who Bought  book2 Also Bought:  book5 , book9 \n",
      "\n",
      "Customers Who Bought  book21 Also Bought:  book22 , book23 \n",
      "\n",
      "Customers Who Bought  book22 Also Bought:  book21 , book23 \n",
      "\n",
      "Customers Who Bought  book23 Also Bought:  book22 , book21 \n",
      "\n",
      "Customers Who Bought  book3 Also Bought:  book1 , book2 \n",
      "\n",
      "Customers Who Bought  book31 Also Bought:  book61 , book6 \n",
      "\n",
      "Customers Who Bought  book4 Also Bought:  book9 , book7 \n",
      "\n",
      "Customers Who Bought  book5 Also Bought:  book2 , book9 \n",
      "\n",
      "Customers Who Bought  book6 Also Bought:  book7 , book31 \n",
      "\n",
      "Customers Who Bought  book61 Also Bought:  book31 , book6 \n",
      "\n",
      "Customers Who Bought  book7 Also Bought:  book17 , book6 \n",
      "\n",
      "Customers Who Bought  book9 Also Bought:  book2 , book0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   Print the book purchased and the books recommended\n",
    "print(\"\\n Books Recommendation as per customer purchase : \\n\")\n",
    "for book in book_recommended:\n",
    "    print(\"Customers Who Bought \", book[0] ,\"Also Bought: \",' , '.join(book[1]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
